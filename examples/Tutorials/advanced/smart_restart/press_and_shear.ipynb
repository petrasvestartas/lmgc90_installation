{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Smart restart\n",
    "\n",
    "The idea of this tutorial is to show how to chain several computations while changing some elements of the pre-processing step in between them.\n",
    "\n",
    "The chosen example is a shear of a 2D sample with thermo-rigids disks in a periodic channel. Because of the periodicity, it is more convenient to use a cluster of disks to generate the walls.\n",
    "This computation is split into two computations:\n",
    "\n",
    "1. First a purely mechanical computation with a vertical force to balance the sample\n",
    "2. A second computation changing:\n",
    "  * the material of the disks to get a thermo-rigid model\n",
    "  * the boundary condition of the upper wall to shear\n",
    "  \n",
    "The point is to keep the exact state of the first computation, the contacts network included! To avoid any confusion, the two computations will be run in different directories named *Press* and *Shear* respectively.\n",
    "\n",
    "## First sample generation\n",
    "\n",
    "It is reminded that:\n",
    "\n",
    "* the walls are cluster of disks\n",
    "* the upper wall has a vertical force boundary condition\n",
    "* the friction coefficient is null during this step\n",
    "* there is no gravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from pylmgc90 import pre\n",
    "\n",
    "# creating directory 'Press/DATBOX' if not existing\n",
    "datbox_path = Path('Press/DATBOX')\n",
    "datbox_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dim = 2\n",
    "\n",
    "#############\n",
    "Friction          = 0.00\n",
    "Friction_wall     = 0.00\n",
    "#############\n",
    "Rmin              = 0.05\n",
    "Rmax              = 0.15\n",
    "\n",
    "lx = 50*Rmax\n",
    "ly = 10*Rmax\n",
    "nb_particles      = 1000\n",
    "#############\n",
    "\n",
    "############## \n",
    "bodies = pre.avatars()\n",
    "mats   = pre.materials()\n",
    "mods   = pre.models()\n",
    "svs    = pre.see_tables()\n",
    "tacts  = pre.tact_behavs()\n",
    "\n",
    "############## creating materials\n",
    "# Note : these are in fact the same materials, just to make a difference between grains and walls\n",
    "tdur = pre.material(name='TDURx',materialType='RIGID',density=2800.)\n",
    "plex = pre.material(name='PLEXx',materialType='RIGID',density=2800.)\n",
    "mats.addMaterial(tdur,plex)\n",
    "\n",
    "############## rigid model creation\n",
    "mod = pre.model(name='rigid', physics='MECAx', element='Rxx2D', dimension=dim)\n",
    "mods.addModel(mod)\n",
    "\n",
    "############## granulo anb box building\n",
    "radii  = pre.granulo_Uniform(nb_particles, Rmin, Rmax)\n",
    "\n",
    "nb_remaining_particles, coor, radii = pre.depositInBox2D(radii, lx, ly)\n",
    "############## loop adding particles:\n",
    "for r, c in zip(radii, coor):\n",
    "    body=pre.rigidDisk( model=mod, material=plex, center=c, r=r, color='BLUEx')\n",
    "    #\n",
    "    bodies += body\n",
    "\n",
    "############## four walls creation with tdur material\n",
    "down = pre.roughWall(center=[0.5*lx, -Rmin], l=lx, r=Rmin, model=mod, material=tdur, color='WALLx')\n",
    "down.imposeDrivenDof(component=1, dofty='vlocy')\n",
    "down.imposeDrivenDof(component=2, dofty='vlocy')\n",
    "down.imposeDrivenDof(component=3, dofty='vlocy')\n",
    "bodies += down\n",
    "\n",
    "up   = pre.roughWall(center=[0.5*lx, ly+Rmin], l=lx, r=Rmin, model=mod, material=tdur, color='WALLx')\n",
    "up.imposeDrivenDof(component=1, dofty='vlocy')\n",
    "up.imposeDrivenDof(component=2, dofty='force',ct=-100000.,rampi=1.)\n",
    "up.imposeDrivenDof(component=3, dofty='vlocy')\n",
    "bodies += up\n",
    "\n",
    "############## interactions management:\n",
    "#   * law declarations\n",
    "#       - particles vs particles and particles va walls\n",
    "l1 = pre.tact_behav(name='iqsc1',law='IQS_CLB',fric=Friction)\n",
    "tacts += l1\n",
    "l2 = pre.tact_behav(name='iqsc2',law='IQS_CLB',fric=Friction_wall)\n",
    "tacts += l2\n",
    "\n",
    "#   * visibility tables declaration\n",
    "#       - between particles of type (disk blue) vs (disk blue)\n",
    "svdkdk = pre.see_table(CorpsCandidat   ='RBDY2', candidat   ='DISKx', colorCandidat   ='BLUEx', behav=l1,\n",
    "                       CorpsAntagoniste='RBDY2', antagoniste='DISKx', colorAntagoniste='BLUEx', alert=Rmin)\n",
    "svs += svdkdk\n",
    "#       - between particles of type (disk blue) vs (disk wall)\n",
    "svdkjc = pre.see_table(CorpsCandidat    ='RBDY2', candidat   ='DISKx', colorCandidat   ='BLUEx', behav=l2,\n",
    "                        CorpsAntagoniste='RBDY2', antagoniste='DISKx', colorAntagoniste='WALLx', alert=Rmin)\n",
    "svs += svdkjc\n",
    "\n",
    "\n",
    "# file writing\n",
    "post = pre.postpro_commands()\n",
    "pre.writeDatbox(dim, mats, mods, bodies, tacts, svs, post=post, datbox_path=datbox_path, gravy=[0.,0.,0.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.visuAvatars(bodies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First computation\n",
    "\n",
    "The sample equilibrium computation under vertical loading. The computation is a classical one, except that:\n",
    "\n",
    "1. the computation is run in the *Press* directory thanks to the `chipy.overall_SetWorkingDirectory` function,\n",
    "2. the periodicity length is given thanks to the `chipy.SetPeriodicCondition`,\n",
    "3. the `chipy.nlgs_SetWithQuickScramble` is used to accelerate solver convergence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylmgc90 import chipy\n",
    "from pylmgc90.chipy import computation\n",
    "\n",
    "dim           = 2\n",
    "Rmax          = 0.15\n",
    "dt            = 1.e-4  # Time step\n",
    "theta         = 0.5    # Time integrator\n",
    "nb_steps      = 5000\n",
    "freq_display  = 1000\n",
    "freq_outFiles = 1000\n",
    "freq_detect   = 1      # Contact detection frequency\n",
    "\n",
    "h5_file       = 'lmgc90.h5'\n",
    "#\n",
    "#         123456789012345678901234567890\n",
    "stype  = 'Stored_Delassus_Loops         '\n",
    "norm   = 'QM/16'\n",
    "tol    = 1e-4\n",
    "relax  = 1.0\n",
    "gs_it1 = 50                    # Minimum number of iterations\n",
    "gs_it2 = 501                   # Maximum number of iterations  = gs_it2 * gs_it1\n",
    "#\n",
    "##############################\n",
    "### INITIALIZE COMPUTATION ###\n",
    "##############################\n",
    "chipy.overall_SetWorkingDirectory('Press')\n",
    "computation.initialize(dim, dt, theta, h5_file=h5_file, logmes=False)\n",
    "chipy.SetPeriodicCondition(xperiod=50*Rmax)\n",
    "chipy.nlgs_SetWithQuickScramble()\n",
    "\n",
    "############################\n",
    "### STARTING COMPUTATION ###\n",
    "############################\n",
    "for k in range(1, nb_steps+1):\n",
    "    if k%500 == 0:\n",
    "        print( f\"computing step {k:4d}/{nb_steps}\")\n",
    "    computation.one_step(stype,norm,tol,relax,gs_it1,gs_it2,freq_outFiles,freq_display)\n",
    "\n",
    "##########################\n",
    "### END OF COMPUTATION ###\n",
    "##########################\n",
    "\n",
    "computation.finalize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading old computation to generate a new one\n",
    "\n",
    "Now to prepare the second computation, it is desired to reload the result of this computation as *pre containers* before applying some changes before writing a new *DATBOX* directory.\n",
    "\n",
    "The two functions to use are:\n",
    "* `pre.readDatbox` to read a *DATBOX* directory and get the associated containers,\n",
    "* `pre.readState` which will read a particular step of either a set of _OUTBOX/*.OUT_ files or an HDF5 file to change the configuration of the different avatars.\n",
    "\n",
    "These two functions will also return a numpy array describing all interactions.\n",
    "\n",
    "The changes to be made are to:\n",
    "* change the friction coefficient\n",
    "* add a velocity boundary condition along y-axis on the upper wall\n",
    "* change the materials and models container to have a thermorigid\n",
    "\n",
    "But first things first, let us start with loading the computation as *pre containers*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fnmatch\n",
    "\n",
    "from pylmgc90 import pre\n",
    "\n",
    "dim = 2\n",
    "mats, mods, bodies, tacts, sees, inters = pre.readDatbox(dim, str(datbox_path))\n",
    "inters = pre.readState(bodies, 'Press/OUTBOX', -1, 'Press/lmgc90.h5', tacts)\n",
    "#reading_step = len(fnmatch.filter(os.listdir('Press/OUTBOX/'), 'DOF.OUT.*'))\n",
    "#inters = pre.readState(bodies, 'Press/OUTBOX', reading_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the containers should be in the same order than before writing the *Press* DATBOX but with the configuration of the computation. It is then possible to change the friction coefficient of the two contact laws."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre.visuAvatars(bodies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change friction parameters of contact laws\n",
    "for k, v in tacts.items():\n",
    "    print( f\"updating friction parameters of law {k}\" )\n",
    "    v.fric = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it is not as straightforward to identify some specific bodies. For example, remembering that the walls have the *WALLx* color, it is really easy to find the two wall avatars. But to know which one is the upper or lower one, either a check on the avatar coordinates, or just remembering in which order they have been added. Once the avatar identify there is no difference with regular boundary condition addition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for wall avatars by color:\n",
    "walls = []\n",
    "for b in bodies:\n",
    "    if b.contactors[0].color == 'WALLx':\n",
    "        walls.append(b)\n",
    "\n",
    "# get the upper wall:\n",
    "upper = walls[0] if walls[0].getNodeCoor()[1] > walls[1].getNodeCoor()[1] else walls[1]\n",
    "\n",
    "# assert that the upper wall is really the second one\n",
    "assert upper is walls[1], \"something strange when looking for upper wall\"\n",
    "\n",
    "# adding boundary conditions in velocity\n",
    "# without changing the existing previous ones on down and up\n",
    "upper.imposeDrivenDof(component=1, dofty='vlocy',ct=1.,rampi=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally the last bit, a little more technical, is to write the thermorigid models. Currently the thermorigid model and material writing is made thanks to external script provided within the current directory of this notebook (*MP_mat.py* and *MP_mod.py*). Thus the logic is:\n",
    "* to reset the material container to be empty,\n",
    "* to write all the avatar containers as usual,\n",
    "* then to write the thermorigid model and materials using the provided scripts.\n",
    "\n",
    "**Beware:** the name of the model and material of each avatar is already defined and identified by a five character string inside each objects. Thus when creating the model and materials, they must be have the same name ! Otherwise there will be error when trying to initialize LMGC90 database when starting the computation part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wall_mat = walls[0].bulks[0].material.nom\n",
    "disk_mat = bodies[0].bulks[0].material.nom\n",
    "print( f\"material name of walls: {wall_mat}\")\n",
    "print( f\"material name of disks: {disk_mat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset materials to use MP ones\n",
    "mats = pre.materials()\n",
    "\n",
    "# creating new directory in which to write DATBOX\n",
    "datbox_path = Path('Shear/DATBOX')\n",
    "datbox_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# write DATBOX in Shear directory\n",
    "post = pre.postpro_commands()\n",
    "pre.writeDatbox(dim, mats, mods, bodies, tacts, sees, inters, post=post, datbox_path=datbox_path, gravy=[0.,0.,0.])\n",
    "\n",
    "# create new thermorigid model/materials\n",
    "import MP_mat\n",
    "import MP_mod\n",
    "\n",
    "#MP_mod.write_thermal_model(T0=0.23e+2,alert=rmax,ldiff='Cylnd',gdiff='discrete',lconv='no',lkine='all',bound='1D__')\n",
    "\n",
    "rmax=0.5\n",
    "lx = 50*rmax\n",
    "\n",
    "MP_mod.write_thermal_model(T0=0.23e+2, alert=rmax, ldiff='Cylnd', gdiff='discrete',\n",
    "                           lconv='no', lkine='all', bound='adia', PATH=str(datbox_path))\n",
    "\n",
    "#MP_mod.write_thermal_source(first=down.number+1,last=down.number+1,T0=100.)\n",
    "#MP_mod.write_thermal_bounds(first=up.number+1,last=up.number+1,T0=1000.,thickness=4*lx,length=2*lx,alpha=1e-1,locus='U')\n",
    "\n",
    "# wall\n",
    "MP_mat.write_thermal_material(name=wall_mat,materialType='THERMO_RIGID',density=7800.,\n",
    "                              anisotropy='isotropic',thermal_conductivity=3.9e+02,specific_heat=3.8e+02,\n",
    "                              thermal_young=1.24e+09,thermal_nu=0.3e+00,PATH=str(datbox_path))\n",
    "# particles\n",
    "MP_mat.write_thermal_material(name=disk_mat,materialType='THERMO_RIGID',density=7800.,\n",
    "                              anisotropy='isotropic',thermal_conductivity=3.9e+02,specific_heat=3.8e+02,\n",
    "                              thermal_young=1.24e+09,thermal_nu=0.3e+00,PATH=str(datbox_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second computation\n",
    "\n",
    "Now a thermorigid computation can be made. The *computations* macro cannot be used in this case and a more old fashionned script content is presented here. The computation still make uses of:\n",
    "\n",
    "* the `chipy.overall_SetWorkingDirectory` function to work in the *Shear* directory,\n",
    "* the `chipy.SetPeriodicCondition to set` the periodicity of the sample,\n",
    "* the `chipy.nlgs_SetWithQuickScramble` to accelerate solver convergence,\n",
    "* the `chipy.RBDY2_FatalDamping`.\n",
    "\n",
    "Furthermore to use the *thermorigid* feature the following functions must also be used:\n",
    "\n",
    "* `chipy.ReadMpBehaviours` during initialization to read the files,\n",
    "* `chipy.mp_solver_RecupTemperature` and `chipy.mp_solver_SolveThermoProblem` after the contact resolution to solve the thermal part.\n",
    "\n",
    "Finally, the *temperature* field is added to the visualization files. This needs several code blocks along the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pylmgc90 import chipy\n",
    "\n",
    "chipy.Initialize()\n",
    "chipy.overall_SetWorkingDirectory('Shear')\n",
    "\n",
    "#############\n",
    "# Parameters\n",
    "#############\n",
    "#\n",
    "# ... of the simulation\n",
    "nb_steps    = 10000\n",
    "dt          = 5.e-4  # Time step\n",
    "theta       = 0.5    # Time integrator\n",
    "freq_detect = 1      # Contact detection frequency\n",
    "Rmax        = 0.15\n",
    "freq_visu   = 100    # Number of visualization files\n",
    "freq_write  = 100    # Number of outputs in file\n",
    "\n",
    "h5_file     = 'lmgc90.h5'\n",
    "\n",
    "#\n",
    "# ... of the computation\n",
    "#         123456789012345678901234567890\n",
    "stype  = 'Stored_Delassus_Loops         '\n",
    "norm   = 'QM/16'\n",
    "tol    = 1e-5\n",
    "relax  = 1.0\n",
    "gs_it1 = 100                   # Minimum number of iterations\n",
    "gs_it2 = 101                   # Maximum number of iterations = gs_it2 * gs_it1\n",
    "chipy.nlgs_SetWithQuickScramble()\n",
    "#\n",
    "#############\n",
    "chipy.utilities_DisableLogMes()      # Log message management\n",
    "#chipy.utilities_EnableLogMes()\n",
    "chipy.checkDirectories()             # Check if all subdirectories are presents\n",
    "chipy.SetDimension(2)                # Set dimension in chipy for dummies  ###\n",
    "\n",
    "#####################\n",
    "### Model reading ###\n",
    "#####################\n",
    "\n",
    "chipy.utilities_logMes('READ BODIES')\n",
    "chipy.ReadBodies()\n",
    "\n",
    "chipy.utilities_logMes('READ BEHAVIOURS')\n",
    "chipy.ReadBehaviours()\n",
    "\n",
    "chipy.utilities_logMes('LOAD BEHAVIOURS')\n",
    "chipy.LoadBehaviours()\n",
    "\n",
    "chipy.utilities_logMes('LOAD TACTORS')\n",
    "chipy.LoadTactors()\n",
    "\n",
    "# THERMO RIGID\n",
    "chipy.ReadMpBehaviours(0,'therm')\n",
    "\n",
    "chipy.ReadIni()\n",
    "#\n",
    "chipy.utilities_logMes('READ DRIVEN DOF')\n",
    "chipy.ReadDrivenDof()\n",
    "############################\n",
    "### End of Model reading ###\n",
    "############################\n",
    "\n",
    "chipy.SetPeriodicCondition(xperiod=50*Rmax)\n",
    "\n",
    "#########################################\n",
    "### Computation parameters definition ###\n",
    "#########################################\n",
    "chipy.utilities_logMes('INIT TIME STEPPING')\n",
    "chipy.TimeEvolution_SetTimeStep(dt)\n",
    "chipy.Integrator_InitTheta(theta)\n",
    "\n",
    "### Init postpro ###\n",
    "chipy.OpenDisplayFiles()\n",
    "chipy.OpenPostproFiles()\n",
    "chipy.InitHDF5(h5_file)\n",
    "\n",
    "### COMPUTE MASS ###\n",
    "chipy.ComputeMass()\n",
    "\n",
    "############################\n",
    "### STARTING COMPUTATION ###\n",
    "############################\n",
    "\n",
    "nbdiskx     = chipy.DISKx_GetNbDISKx()\n",
    "diskx2rbdy2 = chipy.DISKx_GetPtrDISKx2BDYTY()\n",
    "\n",
    "nbjoncx     = chipy.JONCx_GetNbJONCx()\n",
    "joncx2rbdy2 = chipy.JONCx_GetPtrJONCx2BDYTY()\n",
    "\n",
    "nbR2        = chipy.RBDY2_GetNbRBDY2()\n",
    "\n",
    "Th_DISKx = np.zeros([nbdiskx])\n",
    "Th_JONCx = np.zeros([nbjoncx])\n",
    "\n",
    "T_dict = {'DISKx':Th_DISKx, 'JONCx':Th_JONCx}\n",
    "\n",
    "\n",
    "chipy.RBDY2_FatalDamping()\n",
    "\n",
    "for k in range(1, nb_steps+1):\n",
    "    #\n",
    "    if k%500 == 0:\n",
    "        print( f\"computing step {k:4d}/{nb_steps}\")\n",
    "\n",
    "    chipy.IncrementStep()\n",
    "    #\n",
    "    chipy.ComputeFext()\n",
    "    #\n",
    "    chipy.ComputeBulk()\n",
    "    chipy.ComputeFreeVelocity()\n",
    "    #\n",
    "    chipy.SelectProxTactors(freq_detect)\n",
    "    #\n",
    "    chipy.RecupRloc()\n",
    "    chipy.nlgs_ExSolver(stype,norm,tol,relax,gs_it1,gs_it2)\n",
    "    chipy.StockRloc()\n",
    "    #\n",
    "    # THERMO RIGID\n",
    "    #\n",
    "    chipy.mp_solver_RecupTemperature()\n",
    "    chipy.mp_solver_SolveThermoProblem()\n",
    "\n",
    "    #\n",
    "    chipy.ComputeDof()\n",
    "    chipy.UpdateStep()\n",
    "    #\n",
    "    chipy.WriteOut(freq_write)\n",
    "    #\n",
    "    # THERMO RIGID\n",
    "    #\n",
    "    chipy.WriteOutMpValues(freq_write)\n",
    "    #\n",
    "    ### postpro ###\n",
    "    if (k % freq_visu == 0 ):\n",
    "        #\n",
    "        for itacty in range(1,nbdiskx+1,1):\n",
    "            iddiskx = diskx2rbdy2[itacty-1]\n",
    "            idR2 = int(iddiskx[0])\n",
    "            idTy = int(iddiskx[1])\n",
    "            # THERMO RIGID\n",
    "            Th_DISKx[itacty-1] = chipy.RBDY2_GetThermalValue(idR2,idTy)\n",
    "         \n",
    "        for itacty in range(1,nbjoncx+1,1):\n",
    "            idjoncx = joncx2rbdy2[itacty-1]\n",
    "            idR2 = int(idjoncx[0])\n",
    "            idTy = int(idjoncx[1])\n",
    "            # THERMO RIGID\n",
    "            Th_JONCx[itacty-1] = chipy.RBDY2_GetThermalValue(idR2,idTy)\n",
    "\n",
    "        chipy.WriteDisplayFiles(1,T =('tacts',T_dict))\n",
    "     \n",
    "    chipy.WritePostproFiles()\n",
    "\n",
    "    chipy.checkInteractiveCommand()\n",
    "\n",
    "##########################\n",
    "### END OF COMPUTATION ###\n",
    "##########################\n",
    "\n",
    "chipy.CloseDisplayFiles()\n",
    "chipy.ClosePostproFiles()\n",
    "chipy.Finalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!paraview"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
