{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Forenote*: despite the way of working presented here may have an interest to extract direct data without having to reload the whole LMGC90 database, there is a lot of information missing since the geometries of the bodies are not present in the file. As such reading the documentation of [a posteriori management](../../apiPostpro.ipynb) of data with LMGC90 is still, in the authors' sense, the best approach since it only relies on the LMGC90 API.\n",
    "\n",
    "# Post with NumPy\n",
    "\n",
    "It is possible to extract the data stored in the HDF5 file and to store them in a numpy array. The benefit would be to easily access the data stored in an efficient way, without having to wonder how they have been saved in the file.\n",
    "\n",
    "To make things easier, most of the job has been hidden in a `get_numpy_frame` function in the *utils* module next to this notebook.\n",
    "\n",
    "Furthermore, for efficiency's sake, there are some internal data of LMGC90 which, instead of being represented with strings are represented with an integer parameter. For example, to describe if a body is rigid in 2D, instead of using the string `RBDY2` (which is the historical keyword for this), the code use just `1`.\n",
    "\n",
    "So, the raw data extracted from the binary file is not straightforwardly usable. The first thing is to get the mapping between the integer number and the associated string (which is stored inside the file), which is done with the `get_parameters` function of the *utils* module.\n",
    "\n",
    "To understand how these functions were written, the interested reader can have a look into:\n",
    "* *HDF5_basis.ipynb* notebook which is in the *Tutorials/post/by_hand* directory and explains how to read the content of the file\n",
    "* *HDF5_coordination.ipynb* notebook which is in the *Tutorials/post/by_hand* directory and show a simple example of direct information extraction.\n",
    "\n",
    "### Imports\n",
    "\n",
    "So let us start by importing everything needed in the notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "from utils import get_parameters, get_numpy_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "The first thing to get is the different parameters mappings. Use the function aforementionned ; it is then possible to explore the content to get a rough understanding of what is stored in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = get_parameters('../lmgc90.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( parameters.keys() )\n",
    "print( parameters['bdyty'] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to remember this point if there is a need to directly look into the hdf5 file using either the `h5dump` utility (which drop all data in a text file) or using some third party graphical tools allowing to explore the content of your file.\n",
    "\n",
    "For example, by looking into the *VlocRloc* section of a recording, looking into the integer data of particular interaction, the first column describes which type of interaction it is. Having a way to remap that this integer is in fact a classical interaction type of LMGC90 is more convenient :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters['inter_id'][15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rough hierarchy\n",
    "\n",
    "As the HDF name states (**H**ierarchy **D**ata **F**ile), there is a logical construction of the file. Without explaining everything, the requirement to understand how to extract data is to know that there are three groups at the root of the file:\n",
    "* *Simulation* which contains fixed data along the simulation (number of time steps, dimension, integrator...)\n",
    "* *Evolution* which contains subgroup with the pattern name *ID_x* with *x* a number of record which is a increasing integer starting at 1.\n",
    "* *Help* which contains meta data on the content of each field and the parameters mapping.\n",
    "\n",
    "There also some data stored directly into the root group allowing to check the version of LMGC90 with which the file has been generated.\n",
    "\n",
    "Then in an *ID_x* group there may be several subgroups describing:\n",
    "* *RBDY2*\n",
    "* *RBDY3*\n",
    "* *MAILx* which in itself may contain:\n",
    "  * *mecax*\n",
    "  * *therx*\n",
    "  * *porox*\n",
    "* *VlocRloc*\n",
    "\n",
    "Generally speaking, each of this subgroup will have two sets of data associated which are *idata* for integer data and *rdata* with real data.\n",
    "\n",
    "### Extracting a record\n",
    "\n",
    "First thing is, the user must open the file to check how many records are stored and decide which one is to be read.\n",
    "\n",
    "**Warning**: it is really important when opening the HDF5 file for reading, to close it once done with it. Otherwise, even if python is closed, the file itself, mays still considered itself opened and deemed *unavailable* or *already opened* when wanting to access it later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hfile = '../lmgc90.h5'\n",
    "\n",
    "with h5py.File(hfile, 'r') as hf:\n",
    "    nb_record = int( hf['Simulation/nb_record'][()] )\n",
    "\n",
    "print( f\"number of record saved: {nb_record}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_record = 1\n",
    "assert 0 < id_record <= nb_record, \"[ERROR] wrong record number\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is possible to use the `get_numpy_frame` function to extract the data from the file, using the `parameters` dictionnary to remap the integer data to intelligible strings.\n",
    "\n",
    "First thing is now to get two numpy arrays holding all integer and real data for the all the interactions of a given record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basegroup = \"Evolution/ID_\"+str(id_record)\n",
    "\n",
    "hgroup = 'VlocRloc/idata'\n",
    "iinter = get_numpy_frame(hfile, basegroup, hgroup, parameters)\n",
    "\n",
    "hgroup = 'VlocRloc/rdata'\n",
    "rinter = get_numpy_frame(hfile, basegroup, hgroup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the array is generated, each element of the array is described by the `dtype` of the array.\n",
    "Slicing works as usual to access the different elements of the array.\n",
    "To extract a *column* of the array, a list of string of the different fields can be provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( iinter.shape )\n",
    "iinter.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iinter[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iinter[50:75]['inter_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this point on, to quickly extract and manipulate the data of the array, a good understanding of how the [indexing of the array](https://numpy.org/doc/stable/reference/arrays.indexing.html#integer-array-indexing)\n",
    "works and how to efficiently use [mask to extract data](https://numpy.org/doc/stable/reference/arrays.indexing.html#boolean-array-indexing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting each type of interaction...\n",
    "print( 'type of interactions : ', np.unique(iinter['inter_id']) )\n",
    "for i_id in np.unique(iinter['inter_id']):\n",
    "    mask = iinter['inter_id']==i_id\n",
    "    print( i_id, np.sum( mask ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjancence table of the 12 first candidates:\n",
    "list_cd = np.unique(iinter['ibdyty'][:,0])\n",
    "for cd in list_cd[:12]:\n",
    "    mask = iinter['ibdyty'][:,0] == cd\n",
    "    print( f\"candidate {cd} has {np.sum( mask )} antagonist : {iinter['ibdyty'][mask,1]}\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, remember that numpy offers a set of function allowing to select, or compute (sum, min, max) on array extremly efficiently. For example, to compute the mean of normal reaction on all *DKDKx* contacts, one would have to do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the list of DKDKx\n",
    "dkdkx = iinter['inter_id'] == b'DKDKx'\n",
    "dkdkx = dkdkx[:,0]\n",
    "# compute mean of rn\n",
    "np.mean( rinter['rl'][dkdkx,1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute mean of rn only counting when gap is positif\n",
    "gap_ok = rinter['gapTT'] <= 0.\n",
    "gap_ok = gap_ok[:,0]\n",
    "dkdk_gap_ok = np.logical_and( dkdkx, gap_ok )\n",
    "np.mean( rinter['rl'][dkdk_gap_ok,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, to get the coordination number from this list of *DKDKx* interaction which have a null or negative *gapTT*, the adjacent map and coordination number can be generated (in the same way than in the *Tutorials/post/by_hand* notebook example):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cd = np.unique(iinter[dkdk_gap_ok]['ibdyty'])\n",
    "coordination_number = {}\n",
    "for cd in list_cd:\n",
    "    mask = iinter['ibdyty'][:,0] == cd\n",
    "    coordination_number[cd] = np.sum( mask )\n",
    "\n",
    "nbc = np.array( [*coordination_number.values() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "plt.hist( nbc, bins=np.max(nbc) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally a different array can be generated to read the data of rigid bodies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgroup = 'RBDY2/idata'\n",
    "ibody  = get_numpy_frame(hfile, basegroup, hgroup, mapper=parameters)\n",
    "\n",
    "hgroup = 'RBDY2/rdata'\n",
    "rbody  = get_numpy_frame(hfile, basegroup, hgroup)\n",
    "\n",
    "# hgroup = 'MAILx/mecax/flux'\n",
    "# fmeca  = get_numpy_frame(hf, basegroup, hgroup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
